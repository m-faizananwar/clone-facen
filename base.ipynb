{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6ff45a-f43c-4932-8447-0677ec57212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepface in ./.venv/lib/python3.12/site-packages (0.0.93)\n",
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.12/site-packages (2.19.0)\n",
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.12/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: tf-keras in ./.venv/lib/python3.12/site-packages (2.19.0)\n",
      "Requirement already satisfied: requests>=2.27.1 in ./.venv/lib/python3.12/site-packages (from deepface) (2.32.4)\n",
      "Requirement already satisfied: numpy>=1.14.0 in ./.venv/lib/python3.12/site-packages (from deepface) (2.1.3)\n",
      "Requirement already satisfied: pandas>=0.23.4 in ./.venv/lib/python3.12/site-packages (from deepface) (2.3.1)\n",
      "Requirement already satisfied: gdown>=3.10.1 in ./.venv/lib/python3.12/site-packages (from deepface) (5.2.0)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in ./.venv/lib/python3.12/site-packages (from deepface) (4.67.1)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in ./.venv/lib/python3.12/site-packages (from deepface) (11.3.0)\n",
      "Requirement already satisfied: keras>=2.2.0 in ./.venv/lib/python3.12/site-packages (from deepface) (3.10.0)\n",
      "Requirement already satisfied: Flask>=1.1.2 in ./.venv/lib/python3.12/site-packages (from deepface) (3.1.1)\n",
      "Requirement already satisfied: flask-cors>=4.0.1 in ./.venv/lib/python3.12/site-packages (from deepface) (6.0.1)\n",
      "Requirement already satisfied: mtcnn>=0.1.0 in ./.venv/lib/python3.12/site-packages (from deepface) (1.0.0)\n",
      "Requirement already satisfied: retina-face>=0.0.1 in ./.venv/lib/python3.12/site-packages (from deepface) (0.0.17)\n",
      "Requirement already satisfied: fire>=0.4.0 in ./.venv/lib/python3.12/site-packages (from deepface) (0.7.0)\n",
      "Requirement already satisfied: gunicorn>=20.1.0 in ./.venv/lib/python3.12/site-packages (from deepface) (23.0.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.venv/lib/python3.12/site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.12/site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: blinker>=1.9.0 in ./.venv/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in ./.venv/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (8.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in ./.venv/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in ./.venv/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.venv/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in ./.venv/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.12/site-packages (from gdown>=3.10.1->deepface) (4.13.4)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from gdown>=3.10.1->deepface) (3.18.0)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.12/site-packages (from keras>=2.2.0->deepface) (14.0.0)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.12/site-packages (from keras>=2.2.0->deepface) (0.1.0)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.12/site-packages (from keras>=2.2.0->deepface) (0.16.0)\n",
      "Requirement already satisfied: joblib>=1.4.2 in ./.venv/lib/python3.12/site-packages (from mtcnn>=0.1.0->deepface) (1.5.1)\n",
      "Requirement already satisfied: lz4>=4.3.3 in ./.venv/lib/python3.12/site-packages (from mtcnn>=0.1.0->deepface) (4.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.27.1->deepface) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.27.1->deepface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.27.1->deepface) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.27.1->deepface) (2025.7.9)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in ./.venv/lib/python3.12/site-packages (from requests>=2.27.1->deepface) (1.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=2.2.0->deepface) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install deepface tensorflow opencv-python tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c0e10c-423f-41d9-8b8d-50389153472e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 13:54:27.688119: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-09 13:54:27.688493: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-09 13:54:27.690877: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-09 13:54:27.697164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752051267.707674   28527 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752051267.710715   28527 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752051267.718831   28527 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752051267.718840   28527 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752051267.718842   28527 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752051267.718843   28527 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-09 13:54:27.721911: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-09 13:54:28.843414: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<deepface.models.facial_recognition.GhostFaceNet.GhostFaceNetClient at 0x7ff2b4b0e060>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "DeepFace.build_model('GhostFaceNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709fab43-09e9-4983-9f22-f1cd82f99a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = DeepFace.represent(\n",
    "    img_path=\"./photo_2025-07-09_13-43-47.jpg\",\n",
    "    model_name=\"GhostFaceNet\",\n",
    "    detector_backend=\"opencv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e411e9-972f-4d11-863d-27806413cb24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception while processing img1_path",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/GhostFacesNet/.venv/lib/python3.12/site-packages/deepface/modules/verification.py:167\u001b[39m, in \u001b[36mverify.<locals>.extract_embeddings_and_facial_areas\u001b[39m\u001b[34m(img_path, index)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     img_embeddings, img_facial_areas = \u001b[43m__extract_faces_and_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m=\u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/GhostFacesNet/.venv/lib/python3.12/site-packages/deepface/modules/verification.py:234\u001b[39m, in \u001b[36m__extract_faces_and_embeddings\u001b[39m\u001b[34m(img_path, model_name, detector_backend, enforce_detection, align, expand_percentage, normalization, anti_spoofing)\u001b[39m\n\u001b[32m    232\u001b[39m facial_areas = []\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m img_objs = \u001b[43mdetection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43malign\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m=\u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# find embeddings for each face\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/GhostFacesNet/.venv/lib/python3.12/site-packages/deepface/modules/detection.py:105\u001b[39m, in \u001b[36mextract_faces\u001b[39m\u001b[34m(img_path, detector_backend, enforce_detection, align, expand_percentage, grayscale, color_face, normalize_face, anti_spoofing)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m img_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    106\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFace could not be detected in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease confirm that the picture is a face photo \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor consider to set enforce_detection param to False.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    109\u001b[39m     )\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Face could not be detected in ./photo_2025-07-09_13-43-49.jpg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m obj = \u001b[43mDeepFace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m  \u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./photo_2025-07-09_13-43-49.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m  \u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./photo_2025-07-09_13-43-49 (2).jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGhostFaceNet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m  \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopencv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m  \u001b[49m\u001b[43malign\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/GhostFacesNet/.venv/lib/python3.12/site-packages/deepface/DeepFace.py:150\u001b[39m, in \u001b[36mverify\u001b[39m\u001b[34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mverify\u001b[39m(\n\u001b[32m     71\u001b[39m     img1_path: Union[\u001b[38;5;28mstr\u001b[39m, np.ndarray, List[\u001b[38;5;28mfloat\u001b[39m]],\n\u001b[32m     72\u001b[39m     img2_path: Union[\u001b[38;5;28mstr\u001b[39m, np.ndarray, List[\u001b[38;5;28mfloat\u001b[39m]],\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     83\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m     84\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[33;03m    Verify if an image pair represents the same person or different persons.\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m \u001b[33;03m        - 'time' (float): Time taken for the verification process in seconds.\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mverification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m=\u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/GhostFacesNet/.venv/lib/python3.12/site-packages/deepface/modules/verification.py:181\u001b[39m, in \u001b[36mverify\u001b[39m\u001b[34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001b[39m\n\u001b[32m    178\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mException while processing img\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_path\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img_embeddings, img_facial_areas\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m img1_embeddings, img1_facial_areas = \u001b[43mextract_embeddings_and_facial_areas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m img2_embeddings, img2_facial_areas = extract_embeddings_and_facial_areas(img2_path, \u001b[32m2\u001b[39m)\n\u001b[32m    184\u001b[39m min_distance, min_idx, min_idy = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33minf\u001b[39m\u001b[33m\"\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/GhostFacesNet/.venv/lib/python3.12/site-packages/deepface/modules/verification.py:178\u001b[39m, in \u001b[36mverify.<locals>.extract_embeddings_and_facial_areas\u001b[39m\u001b[34m(img_path, index)\u001b[39m\n\u001b[32m    167\u001b[39m         img_embeddings, img_facial_areas = __extract_faces_and_embeddings(\n\u001b[32m    168\u001b[39m             img_path=img_path,\n\u001b[32m    169\u001b[39m             model_name=model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    175\u001b[39m             anti_spoofing=anti_spoofing,\n\u001b[32m    176\u001b[39m         )\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mException while processing img\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_path\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m img_embeddings, img_facial_areas\n",
      "\u001b[31mValueError\u001b[39m: Exception while processing img1_path"
     ]
    }
   ],
   "source": [
    "obj = DeepFace.verify(\n",
    "  img1_path = \"./photo_2025-07-09_13-43-49.jpg\", \n",
    "  img2_path = \"./photo_2025-07-09_13-43-49 (2).jpg\",\n",
    "  model_name=\"GhostFaceNet\",\n",
    "  detector_backend=\"opencv\",\n",
    "  align = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82c907-f8ce-42ce-8ef1-ce2c411bafee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-07-09 14:09:03 - Searching ./photo_2025-07-09_13-57-48.jpg in 13 length datastore\n",
      "25-07-09 14:09:04 - find function duration 0.515427827835083 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[                              identity  \\\n",
       " 0  my_db/photo_2025-07-09_13-57-48.jpg   \n",
       " \n",
       "                                        hash  target_x  target_y  target_w  \\\n",
       " 0  55970fef6881180878b3fbe5ca433b16a9971f1f       146       414       636   \n",
       " \n",
       "    target_h  source_x  source_y  source_w  source_h  threshold      distance  \n",
       " 0       636       146       414       636       636       0.65 -2.220446e-16  ]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = DeepFace.find(\n",
    "  img_path = \"./photo_2025-07-09_13-57-48.jpg\", \n",
    "  db_path = \"my_db\", \n",
    "  model_name=\"GhostFaceNet\",\n",
    "  detector_backend=\"opencv\",\n",
    "  align = True,\n",
    ")# Simplified Project Scope: Offline Face Recognition Attendance System\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project delivers a streamlined, offline attendance system that uses face recognition combined with anti-spoofing (liveness detection). The solution focuses on essential features for robustness, ease of use, and quick deployment.\n",
    "\n",
    "## 1. Core Workflow\n",
    "\n",
    "**Main Steps:**\n",
    "1. **Anti-Spoofing:** The system checks if the face detected is from a live person (not a photo or screen).\n",
    "2. **Attendance Logging:** If the face is real, the system recognizes the employee and records the check-in time in a local database.\n",
    "3. **Employee Management:** New employees can be added, including automatic retraining/registration.\n",
    "\n",
    "## 2. Technical Architecture\n",
    "\n",
    "### Anti-Spoofing\n",
    "\n",
    "- Detects if the camera input is a live person using passive liveness models (e.g., MiniFASNet).\n",
    "- Prevents spoof attempts with photos, videos, or masks.\n",
    "- Seamlessly integrates by running on each detected face before allowing recognition or logging.\n",
    "\n",
    "### Face Recognition & Attendance\n",
    "\n",
    "- After liveness is confirmed, the system performs automated face recognition with a lightweight model (e.g., GhostFaceNet).\n",
    "- Matches embeddings against a local employee database.\n",
    "- Records the employee ID, time, and liveness status in a secure attendance log.\n",
    "\n",
    "### Employee Addition & Automatic Enrollment\n",
    "\n",
    "- The admin can add a new employee with one or more face photos.\n",
    "- The system extracts embeddings and updates the local database automatically—no manual retraining required.\n",
    "- Supports easy updates as the employee roster changes.\n",
    "\n",
    "## 3. Implementation Details\n",
    "\n",
    "### Minimal Hardware & Software\n",
    "\n",
    "- **Device:** Raspberry Pi 4 (4GB or higher), mid-range PC, or similar ARM/x86 edge platform.\n",
    "- **Camera:** 720p or higher (USB webcam, Pi Cam).\n",
    "- **Storage:** 32GB+ SD card or SSD.\n",
    "- **Operating System:** Linux or Windows.\n",
    "\n",
    "### Recommended Technology Stack\n",
    "\n",
    "| Function            | Stack                        |\n",
    "|---------------------|-----------------------------|\n",
    "| Face Detection      | OpenCV                       |\n",
    "| Anti-Spoofing       | MiniFASNet or DeepFace API   |\n",
    "| Face Recognition    | GhostFaceNet (via DeepFace)  |\n",
    "| Database            | SQLite3 (local file)         |\n",
    "| Backend/Script      | Python 3.x                   |\n",
    "| UI (optional)       | Simple CLI or Web Dashboard  |\n",
    "\n",
    "## 4. Basic System Workflow\n",
    "\n",
    "1. **Start System:** Camera feed runs; system awaits faces.\n",
    "2. **Detect Face:** Extract face region from camera input.\n",
    "3. **Liveness Check:** \n",
    "   - If *not real*: Discard input, prompt for retry.\n",
    "   - If *real*: Proceed to next step.\n",
    "4. **Recognition:**\n",
    "   - Match face against database of registered employees.\n",
    "   - If matched: Log employee and check-in time.\n",
    "   - If not: Optionally prompt for enrollment.\n",
    "5. **Employee Addition:**\n",
    "   - Admin adds a new employee with face images via dashboard or CLI.\n",
    "   - System processes/uploaded images, extracts features, auto-updates database.\n",
    "6. **Database:**\n",
    "   - Stores employee details, face embeddings, attendance events (employee, date/time, liveness status).\n",
    "\n",
    "## 5. Key Features and Recommendations\n",
    "\n",
    "- **Offline capable:** All recognition and recording works with no internet.\n",
    "- **Privacy:** No videos/photos stored unless explicitly needed.\n",
    "- **Scalability:** Supports dozens to hundreds of employees with low hardware requirements.\n",
    "- **Simplicity:** No manual model retraining required for new employees; system updates embeddings automatically.\n",
    "- **Security:** Anti-spoofing blocks fake attempts; records liveness check results in attendance log.\n",
    "\n",
    "## 6. High-Level Table: System Responsibilities\n",
    "\n",
    "| Step               | Automatic? | Admin Input Needed? | Notes                           |\n",
    "|--------------------|:----------:|:-------------------:|---------------------------------|\n",
    "| Anti-spoofing      | Yes        | No                  | Always runs before recognition  |\n",
    "| Face recognition   | Yes        | No                  | Runs on passing liveness check  |\n",
    "| Attendance logging | Yes        | No                  | Data saved to local database    |\n",
    "| Employee add/update| Yes        | Yes                 | Via dashboard/CLI               |\n",
    "| Model retraining   | Yes        | No                  | Automatic, seamless for admin   |\n",
    "\n",
    "## 7. Deployment Guidelines\n",
    "\n",
    "- Plug in camera and power up device.\n",
    "- Launch the attendance script or dashboard.\n",
    "- Register employees via interface (add name and photos).\n",
    "- System is now live: faces are checked for liveness, recognized, and attendance is logged in real time.\n",
    "\n",
    "**Ongoing Tasks:**\n",
    "- Review attendance records in the database.\n",
    "- Add or remove employees as needed; no manual system restarts required.\n",
    "\n",
    "**Summary:**  \n",
    "The project is focused, requiring only essential components (live face check, employee verification, logging, and simple admin interface). Lightweight models and offline-capable code ensure reliable, efficient operation even on low-cost hardware. Automated database updates and enrollment minimize administrative effort and support smooth scaling.\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab325aa-aa22-46c9-87bf-ce2f99ebb525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Empty DataFrame\n",
       " Columns: [identity, hash, target_x, target_y, target_w, target_h, source_x, source_y, source_w, source_h, threshold, distance]\n",
       " Index: []]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e3208-b709-4303-8467-baa1c38c86a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
